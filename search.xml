<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[jenkins更换国内源]]></title>
    <url>%2Fjenkins%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90.html</url>
    <content type="text"><![CDATA[更换国内源123456$ cd &#123;你的Jenkins工作目录&#125;/updates #进入更新配置位置$ vim default.json #这个Json文件与上边的配置文件是相同的# 使用vim的命令，如下，替换所有插件下载的url:1,$s/https:\/\/updates.jenkins.io\/download/https:\/\/mirrors.tuna.tsinghua.edu.cn\/jenkins/g# 替换连接测试url:1,$s/http:\/\/www.google.com/https:\/\/www.baidu.com/g]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令行查询mysql大小]]></title>
    <url>%2F%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9F%A5%E8%AF%A2mysql%E5%A4%A7%E5%B0%8F.html</url>
    <content type="text"><![CDATA[我们的数据库空间不足，需要找出哪些库和哪些表占用比较大的空间。具体步骤：1.查看该数据库实例下所有库大小，得到的结果是以MB为单位（除1024为KB，再除1024为MB），下同12345678&gt; use information_schema&gt; select table_schema,sum(data_length)/1024/1024 as data_length,sum(index_length)/1024/1024 as index_length,sum(data_length+index_length)/1024/1024 as sum from tables;+--------------------+--------------+--------------+--------------+| table_schema | data_length | index_length | sum |+--------------------+--------------+--------------+--------------+| information_schema | 554.23122311 | 163.24804688 | 717.47926998 |+--------------------+--------------+--------------+--------------+1 row in set (0.32 sec) 2.查看该数据库实例下各个库大小123456789101112131415161718&gt; use information_schema&gt; select table_schema,sum(data_length)/1024/1024 as data_length,sum(index_length)/1024/1024 as index_length,sum(data_length+index_length)/1024/1024 as sum from tables group by table_schema;+--------------------+--------------+--------------+--------------+| table_schema | data_length | index_length | sum |+--------------------+--------------+--------------+--------------+| coolnull1 | 0.49992847 | 0.54492188 | 1.04485035 || coolnull | 13.79830647 | 0.74121094 | 14.53951740 || coolnull2 | 0.00114059 | 0.05078125 | 0.05192184 || coolnull3 | 101.22271824 | 1.88183594 | 103.10455418 || coolnull4 | 14.25625229 | 2.78710938 | 17.04336166 || information_schema | 0.00000000 | 0.00781250 | 0.00781250 || mysql | 0.51842022 | 0.08691406 | 0.60533428 || coolnull5 | 0.79851532 | 0.05175781 | 0.85027313 || coolnull6 | 16.85469151 | 1.04882813 | 17.90351963 || zabbix | 404.59375000 | 153.34375000 | 557.93750000 || zabbix_proxy | 1.68750000 | 2.70312500 | 4.39062500 |+--------------------+--------------+--------------+--------------+11 rows in set (0.44 sec) 3.查看coolnull库各表大小123456789101112131415161718&gt; use information_schema&gt; select table_name,data_length/1024/1024 as data_length,index_length/1024/1024 as index_length,(data_length+index_length)/1024/1024 as sum from tables where table_schema='coolnull';+-----------------------+-------------+--------------+------------+| table_name | data_length | index_length | sum |+-----------------------+-------------+--------------+------------+| wp_commentmeta | 5.99062729 | 0.20312500 | 6.19375229 || wp_comments | 2.07605743 | 0.07031250 | 2.14636993 || wp_links | 0.00066376 | 0.00292969 | 0.00359344 || wp_options | 0.60661697 | 0.01953125 | 0.62614822 || wp_postmeta | 0.18944931 | 0.08496094 | 0.27441025 || wp_posts | 4.82567596 | 0.16503906 | 4.99071503 || wp_term_relationships | 0.03670979 | 0.08691406 | 0.12362385 || wp_term_taxonomy | 0.03935623 | 0.03417969 | 0.07353592 || wp_terms | 0.03020859 | 0.06054688 | 0.09075546 || wp_usermeta | 0.00271606 | 0.00976563 | 0.01248169 || wp_users | 0.00022507 | 0.00390625 | 0.00413132 |+-----------------------+-------------+--------------+------------+11 rows in set (0.00 sec) 引用 http://coolnull.com/3934.html 结果。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[解决iotop不能使用的问题]]></title>
    <url>%2F%E8%A7%A3%E5%86%B3iotop%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[安装iotop工具，想要查看磁盘读写情况，发现运行报错，报错如下：1234567891011121314151617181920212223242526Traceback (most recent call last): File "/sbin/iotop", line 17, in &lt;module&gt; main() File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 620, in main main_loop() File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 610, in &lt;lambda&gt; main_loop = lambda: run_iotop(options) File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 508, in run_iotop return curses.wrapper(run_iotop_window, options) File "/usr/lib64/python2.7/curses/wrapper.py", line 43, in wrapper return func(stdscr, *args, **kwds) File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 501, in run_iotop_window ui.run() File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 155, in run self.process_list.duration) File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 434, in refresh_display lines = self.get_data() File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 415, in get_data return list(map(format, processes)) File "/usr/lib/python2.7/site-packages/iotop/ui.py", line 388, in format cmdline = p.get_cmdline() File "/usr/lib/python2.7/site-packages/iotop/data.py", line 292, in get_cmdline proc_status = parse_proc_pid_status(self.pid) File "/usr/lib/python2.7/site-packages/iotop/data.py", line 196, in parse_proc_pid_status key, value = line.split(':\t', 1)ValueError: need more than 1 value to unpack google了一下，解决方法如下：vi /usr/lib/python2.7/site-packages/iotop/data.py跳到196行，修改如下内容：原代码123456789def parse_proc_pid_status(pid): result_dict = &#123;&#125; try: for line in open('/proc/%d/status' % pid): key, value = line.split(':\t', 1) result_dict[key] = value.strip() except IOError: pass # No such process return result_dict 修改为：123456789101112def parse_proc_pid_status(pid): result_dict = &#123;&#125; try: for line in open('/proc/%d/status' % pid): try: key, value = line.split(':\t', 1) except: break result_dict[key] = value.strip() except IOError: pass # No such process return result_dict 保存退出，运行iotop正常。]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx反向代理websocket]]></title>
    <url>%2Fnginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86websocket.html</url>
    <content type="text"><![CDATA[1.原理一般我们开发的WebSocket服务程序使用ws协议，明文的。但是怎样让它安全的通过互联网传输呢？这时候可以通过nginx在客户端和服务端直接做一个转发了， 客户端通过wss访问，然后nginx和服务端通过ws协议通信。 2.配置当前服务器放在内网，所以直接用http协议演示。新建nginx配置文件/etc/nginx/conf.d/websocket.conf，内容如下:123456789101112131415161718upstream websocket &#123; server 127.0.0.1:9999; # appserver_ip:ws_port&#125;server &#123; listen 80; location = /ws/ &#123; proxy_pass http://websocket; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection "upgrade"; &#125;&#125; 解释一下关键配置：最重要的就是在反向代理的配置中增加了如下两行，其它的部分和普通的HTTP反向代理没有任何差别。12proxy_set_header Upgrade $http_upgrade;proxy_set_header Connection "upgrade"; 这里面的关键部分在于HTTP的请求中多了如下头部：这两个字段表示请求服务器升级协议为WebSocket。服务器处理完请求后，响应如下报文：1234# 状态码为101HTTP/1.1 101 Switching ProtocolsUpgrade: websocketConnection: upgrade 告诉客户端已成功切换协议，升级为Websocket协议。握手成功之后，服务器端和客户端便角色对等，就像普通的Socket一样，能够双向通信。 不再进行HTTP的交互，而是开始WebSocket的数据帧协议实现数据交换。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[vps 搭建梯子攻略]]></title>
    <url>%2Fvps%E6%90%AD%E5%BB%BA%E6%A2%AF%E5%AD%90%E6%94%BB%E7%95%A5.html</url>
    <content type="text"><![CDATA[因为某些原因，我们通过vps搭建梯子访问外网，但是一般速度都不快，需要安装一些工具进行加速。 1.安装bbr内核1cd /usr/src &amp;&amp; wget -N --no-check-certificate "https://raw.githubusercontent.com/chiakge/Linux-NetSpeed/master/tcp.sh" &amp;&amp; chmod +x tcp.sh &amp;&amp; ./tcp.sh 注意在弹出的安装界面首先选择1，安装BBR内核,安装过程可能时间较长,耐心等待。 2.安装BBR魔改版加速1cd /usr/src &amp;&amp; ./tcp.sh 在弹出安装界面,输入5,然后回车，使用BBR魔改版加速，等待安装完成提示bbr启动成功即可。 3.安装shadowsocks1cd /usr/src/ &amp;&amp; wget -N --no-check-certificate "https://raw.githubusercontent.com/yubinhong/tools/master/shadowsocks-all.sh" &amp;&amp; chmod +x shadowsocks-all.sh &amp;&amp; ./shadowsocks-all.sh 按照提示安装就可以了。]]></content>
      <categories>
        <category>vps</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[获取本机IP地址]]></title>
    <url>%2F%E8%8E%B7%E5%8F%96%E6%9C%AC%E6%9C%BAIP%E5%9C%B0%E5%9D%80.html</url>
    <content type="text"><![CDATA[我在家里放了一个树莓派，作为服务器使用，经常需要登陆使用，但是家里的网络是动态IP，无奈只能使用ddns（动态dns）的方式。之前使用的是https://dns.he.net/，但是这个经常会被墙。我现在使用的是python获取本机IP地址，然后通过cloudflare的API更新IP解析，实现ddns的效果。 python脚本：1234567891011121314151617181920#!/usr/bin/python#date: 2019-05-09#author: ybhfrom lxml import etreeimport requestsurl = "https://ip.newb.ga"r = requests.get(url)ip = r.json()['ip']print(ip)cloudflare_api = "https://api.cloudflare.com/client/v4/zones/xxxxxxxxxxxxxxxxxxx/dns_records/xxxxxxxxxxxxxxxxxxxxxxxx"params = &#123;&#125;params['type'] = 'A'params['name'] = 'git'params['content'] = str(ip)headers = &#123;"Content-Type": "application/json", "X-Auth-Email": "704523059@qq.com", "X-Auth-Key": "xxxxxxxxxxxxxxxxxxxxxxxxxxx"&#125;req = requests.put(cloudflare_api, json=params, headers=headers)print(req.text) 其中使用到的https://ip.newb.ga是自己写的一个服务，可以看我的github.然后设置定时跑脚本，更新IP。现在就可以愉快的连接树莓派了。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[php 7.2 安装mcrypt扩展]]></title>
    <url>%2Fphp-7-2-%E5%AE%89%E8%A3%85mcrypt%E6%89%A9%E5%B1%95.html</url>
    <content type="text"><![CDATA[微信的接口需要使用到mcrypt加解密，但是php 7.1开始已经移除mcrypt扩展，需要自行安装。 1.环境12系统：centos 7PHP: 7.2.10 2.安装依赖包1yum install libmcrypt libmcrypt-devel mcrypt mhash 3.安装mcrypt扩展123456wget http://pecl.php.net/get/mcrypt-1.0.2.tgztar xf mcrypt-1.0.2.tgzcd mcrypt-1.0.2/usr/local/web/php/bin/phpize./configure --with-php-config=/usr/local/web/php/bin/php-config &amp;&amp; make &amp;&amp; make installvim /usr/local/web/php/etc/php.ini 12345..................#在最后面加上扩展extension=mcrypt.so 4.重载php-fpm配置1kill -USR2 `cat /var/run/php.pid` #php-fpm可以通过信号重载配置]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ELK 使用系列 四、基于elastalert的日志告警]]></title>
    <url>%2FELK-%E4%BD%BF%E7%94%A8%E7%B3%BB%E5%88%97-%E5%9B%9B%E3%80%81%E5%9F%BA%E4%BA%8Eelastalert%E7%9A%84%E6%97%A5%E5%BF%97%E5%91%8A%E8%AD%A6.html</url>
    <content type="text"><![CDATA[前面已经介绍了ELK搭建和使用，日志已经收集起来，当日志出现异常，我们需要第一时间知道，而我们又不能每时每刻都在查看日志，这时候我们就可以用上elastalert了。 一、elastalert 的安装Elastalert是Yelp公司用python2写的一个报警框架(目前支持python2.6和2.7，不支持3.x),github地址为https://github.com/Yelp/elastalert相关依赖可以查看文档.文档中使用的ubuntu 14.x，我使用的是centos，这个不影响使用。 安装使用pip安装1pip install elastalert 或者基于源码安装123git clone https://github.com/Yelp/elastalert.gitpython setup.py installpip install -r requirements.txt 二、设置elasticsearch索引参见setting-up-elasticsearchelastalert-create-index 这个命令会在elasticsearch创建索引，这不是必须的步骤，但是强烈建议创建。因为对于，审计，测试很有用，并且重启elastalert不影响计数和发送alert,默认情况下，创建的索引叫 elastalert_status.12345elastalert-create-indexNew index name (Default elastalert_status)Name of existing index to copy (Default None)New index elastalert_status createdDone! 三、配置文件12mkdir /data/alert_rule -pvi /data/alert_rule/config.yaml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# This is the folder that contains the rule yaml files# Any .yaml file will be loaded as a rulerules_folder: /data/alert_rule/# How often ElastAlert will query Elasticsearch# The unit can be anything from weeks to secondsrun_every: minutes: 1# ElastAlert will buffer results from the most recent# period of time, in case some log sources are not in real timebuffer_time: minutes: 15# The Elasticsearch hostname for metadata writeback# Note that every rule can have its own Elasticsearch hostes_host: 192.168.2.16# The Elasticsearch portes_port: 10086# The AWS region to use. Set this when using AWS-managed elasticsearch#aws_region: us-east-1# The AWS profile to use. Use this if you are using an aws-cli profile.# See http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-getting-started.html# for details#profile: test# Optional URL prefix for Elasticsearch#es_url_prefix: elasticsearch# Connect with TLS to Elasticsearch#use_ssl: True# Verify TLS certificates#verify_certs: True# GET request with body is the default option for Elasticsearch.# If it fails for some reason, you can pass 'GET', 'POST' or 'source'.# See http://elasticsearch-py.readthedocs.io/en/master/connection.html?highlight=send_get_body_as#transport# for details#es_send_get_body_as: GET# Option basic-auth username and password for Elasticsearch#es_username: someusername#es_password: somepassword# Use SSL authentication with client certificates client_cert must be# a pem file containing both cert and key for client#verify_certs: True#ca_certs: /path/to/cacert.pem#client_cert: /path/to/client_cert.pem#client_key: /path/to/client_key.key# The index on es_host which is used for metadata storage# This can be a unmapped index, but it is recommended that you run# elastalert-create-index to set a mappingwriteback_index: elastalert_statusdisable_rules_on_error: false# If an alert fails for some reason, ElastAlert will retry# sending the alert until this time period has elapsedalert_time_limit: days: 2realert: 0old_query_limit: days: 1 1vim /data/alert_rule/example_rule.yaml 123456789101112131415161718192021# From example_rules/example_frequency.yamles_host: 192.168.2.16es_port: 10086name: xxxxx Alert Log#type: frequencytype: anyindex: logstash-*num_events: 1timeframe: minutes: 1filter: - query: - query_string: query: "message:'Traceback' OR message:*Exception* OR source:*Defend*"alert:- "alert_plugin.wechat_qiye_alert.WeChatAlerter"agent_id: "1000006"#party_id: "7"user_id: "@all" 这边告警插件使用自己编写的，基于企业微信进行告警。详情可以查看我的github项目wxapi. 1234mkdir /data/alert_rule/alert_plugincd /data/alert_rule/alert_plugintouch __init__.pyvim wechat_qiye_alert.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#! /usr/bin/env python# -*- coding: utf-8 -*-import jsonimport datetimefrom elastalert.alerts import Alerter, BasicMatchStringfrom requests.exceptions import RequestExceptionfrom elastalert.util import elastalert_logger,EAException #[感谢minminmsn分享](https://github.com/anjia0532/elastalert-wechat-plugin/issues/2#issuecomment-311014492)import requestsimport hashlibimport timeimport sysclass WeChatAlerter(Alerter): def __init__(self, *args): super(WeChatAlerter, self).__init__(*args) self.agent_id = self.rule.get('agent_id', '1000006') self.user_id = self.rule.get('user_id', '@all') def create_default_title(self, matches): subject = 'ElastAlert: %s' % (self.rule['name']) return subject def alert(self, matches): matches2 = [] for match in matches: match2 = &#123;&#125; if len(match['message']) &gt; 1024: match['message'] = match['message'][:1024] + '...' match2['host_name'] = match['fields']['feature'] match2['aws_host'] = match['host']['name'] match2['source'] = match['source'] match2['message'] = match['message'] match2['time'] = match['@timestamp'] matches2.append(match2) if "wallet" in match2['host_name'] or "wallet" in match2['source']: if "qa" in match2['host_name']: agent_id = '0' else: agent_id = '100xxxx' elif "engine" in match2['host_name']: agent_id = '100xxxx' elif "api" in match2['host_name'] or "admin" in match2['host_name'] or "php" in match2['host_name']: agent_id = '100xxxx' else: agent_id = '100xxxx' body = self.create_alert_body(matches2) if agent_id != '0': self.senddata(body, agent_id) elastalert_logger.info("send message to %s" % (agent_id)) def senddata(self, content, agent_id): url="http://xx.xx.xx/api/v2/alert" data = &#123;&#125; data['user']=self.user_id data['agent_id']=agent_id data['content']=content current_time=int(time.time()) data['time']='%s' % current_time secure_word='KM1yeVcFbrL44ZGv' + '%s' % current_time s=hashlib.md5() s.update(secure_word.encode(encoding='utf-8')) data['signature']=s.hexdigest() req=requests.post(url, data=data) elastalert_logger.info("send message and response: %s" % (req.content)) def get_info(self): return &#123;'type': 'WeChatAlerter'&#125; 四、启动elastalert我使用supervisor进行管理进程12yum install supervisorvim /etc/supervisor.d/alertalert.ini 1234567891011121314[program:elastalert]command = python -m elastalert.elastalert --verbose --rule example_rule.yamlstdout_logfile = /data/logs/elastalert/startup.logstderr_logfile = /data/logs/elastalert/error.loguser = onecafedirectory = /data/alert_rule;environment = PYTHONPATH="$PYTHONPATH:/home/wbops/engine/bullet-comments-reflector"environment=LC_ALL='en_US.UTF-8',LANG='en_US.UTF-8',PYTHONPATH="$PYTHONPATH:/data/alert_rule/"autostart = truestartsecs = 5autorestart = truestartretries = 3stdout_logfile_maxbytes=5MBstdout_logfile_backups=5 最后进行启动12systemctl start supervisordsupervisorctl status 1elastalert RUNNING pid 7010, uptime 3 days, 7:04:12 至此结束。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何将自己的开源项目发布到f-droid]]></title>
    <url>%2F%E5%A6%82%E4%BD%95%E5%B0%86%E8%87%AA%E5%B7%B1%E7%9A%84%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E5%8F%91%E5%B8%83%E5%88%B0f-droid.html</url>
    <content type="text"><![CDATA[本人所在公司现在想要把公司的一个开源项目发布到f-droid，研究了一周，走了许多弯路，现记录于此，谨防遗忘。 1.注册一个gitlab.com的账号，fork fdroiddata项目，用于pull request。2.安装fdroidserver（ubuntu 18.04）1234git clone https://gitlab.com/fdroid/fdroidserver.gitexport PATH="$PATH:$PWD/fdroidserver"cd $PWD/fdroidserver./makebuildserver #这个会去下载android sdk,gradle等编译工具。 makebuildserver这个步骤会持续比较长的时间，之后会出现报错，这是因为在构建buildserver因系统环境导致的，这个可以跳过，不影响后续的步骤。 3.初始化1234git clone https://gitlab.com/xxx/fdroiddata.gitcd fdroiddatafdroid init #create a base config.py and signing keys fdroid readmeta #Make sure fdroid works and reads the metadata files properly 4.导入开源项目1fdroid import --url https://github.com/foo/bar --subdir app 5.配置项目的metadatavim metadata/app.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485# F-Droid metadata template## See http://f-droid.org/manual for more details# and the Metadata reference# https://f-droid.org/docs/Build_Metadata_Reference/## Fields that are commented out are optional## Single-line fields start right after the colon (with a whitespace).Categories: (use those which apply) - Connectivity - Development - Games - Graphics - Internet - Money - Multimedia - Navigation - Phone &amp; SMS - Reading - Science &amp; Education - Security - Sports &amp; Health - System - Theming - Time - WritingLicense: (identifier from https://spdx.org/licenses)# Website: (web link)SourceCode: (web link)# IssueTracker: (web link)# Changelog: (web link)# Donate: (web link)# FlattrID: (number)# LiberapayID: (number)# Bitcoin: (bitcoin address)Summary: (one sentence, no more than 30-50 chars, no trailing punctuation)Description: |- Description of what the app does, starting on a new line. It should be as objective as possible and wrapped at 80 chars (except links and list items). A blank line means a line break, i.e. the end of a paragraph. Bulleted lists can be used: * Item 1 * Item 2 Links can be added like this: [https://github.com/org/project/raw/HEAD/res/raw/changelog.xml Changelog] Links to other apps too: [[some.other.app]]RepoType: (git, git-svn, svn, hg or bzr)Repo: (repo url, preferably https)# At least one for new appsBuilds: - versionName: '1.0' versionCode: 1 commit: v1.0 subdir: app # submodules: true gradle: - yes # output: some.apk # prebuild: sed -i -e# For a complete list of possible flags, see the manual# MaintainerNotes: |-# Here go the notes to take into account for future updates, builds, etc.# Will be published in the wiki if present.# The following options are described at this location:# https://f-droid.org/docs/Build_Metadata_Reference/#UpdateCheckModeAutoUpdateMode: (see the manual)UpdateCheckMode: (see the manual)CurrentVersion: (current version name)CurrentVersionCode: (current version code, i.e. number) 修改相应内容。 6.编译测试12345fdroid readmeta #确认app.yml语法没有问题fdroid rewritemeta app #将app.yml格式化fdroid lint app #再次确认app.yml没有问题fdroid build -v -l app #编译测试P.S. 根据项目环境，可能需要安装相应的android ndk，配置完之后一般就没有了问题。 如果在编译过程中还有问题，可以查看fdroid 帮助文档。]]></content>
      <categories>
        <category>f-droid</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ubuntu版本升级]]></title>
    <url>%2Fubuntu%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7.html</url>
    <content type="text"><![CDATA[公司里有一台服务器的系统是ubuntu 16.04，现在想要升级到18.04，以下是升级步骤： 1、安装update-manager-core1sudo apt install update-manager-core 2、修改/etc/update-manager/release-upgrades12sudo vim /etc/update-manager/release-upgrades修改Prompt为lts 3、升级1sudo sudo do-release-upgrade]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[zabbix小版本升级]]></title>
    <url>%2Fzabbix%E5%B0%8F%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7.html</url>
    <content type="text"><![CDATA[我们公司之前使用的zabbix版本为3.4.10,因为安全问题,现在要把版本升级到3.4最高版本3.4.15。升级步骤如下：1.备份数据库和告警脚本12345mkdir -p /zabbix_dir/&#123;sql,scripts&#125; #创建备份目录cd /zabbix_dir/sqlmysqldump -uzabbix -pzabbix --opt --skip-lock-tables --flush-logs --database zabbix --ignore-table=zabbix.history --ignore-table=zabbix.history_log --ignore-table=zabbix.history_str --ignore-table=zabbix.history_text --ignore-table=zabbix.history_uint --ignore-table=zabbix.trends --ignore-table=zabbix.trends_uint &gt; zabbix.sql #备份数据库cd ../scriptscp -a /usr/lib/zabbix/alertscripts . #备份告警脚本 2.升级安装zabbix-serverubuntu 16.0412345wget https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/ubuntu/pool/main/z/zabbix/zabbix-server-mysql_3.4.15-1+xenial_amd64.debwget https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/ubuntu/pool/main/z/zabbix/zabbix-frontend-php_3.4.15-1+xenial_all.debdpkg -i zabbix-server-mysql_3.4.15-1+xenial_amd64.debdpkg -i zabbix-frontend-php_3.4.15-1+xenial_all.debsystemctl restart zabbix-serveer centos 7.x12yum install https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-server-mysql-3.4.15-1.el7.x86_64.rpmsystemctl restart zabbix-server 3.升级安装zabbix-proxy(如果有)ubuntu 16.04123wget https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/ubuntu/pool/main/z/zabbix/zabbix-proxy-mysql_3.4.15-1+xenial_amd64.debdpkg -i zabbix-proxy-mysql_3.4.15-1+xenial_amd64.debsystemctl restart zabbix-proxy centos 7.x12yum install https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-proxy-mysql-3.4.15-1.el7.x86_64.rpmsystemctl restart zabbix-proxy 4.升级安装zabbix-agent(可选)ubuntu 16.04123wget https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/ubuntu/pool/main/z/zabbix/zabbix-agent_3.4.15-1+xenial_amd64.debdpkg -i zabbix-agent_3.4.15-1+xenial_amd64.debsystemctl restart zabbix-agent centos 7.x12yum install https://mirrors.tuna.tsinghua.edu.cn/zabbix/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.15-1.el7.x86_64.rpmsystemctl restart zabbix-agent]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[linux下的&、bg、fg和jobs命令]]></title>
    <url>%2Flinux%E4%B8%8B%E7%9A%84-%E3%80%81bg%E3%80%81fg%E5%92%8Cjobs%E5%91%BD%E4%BB%A4.html</url>
    <content type="text"><![CDATA[我们在linux下有时会需要把服务放到后台去运行，下面就将讲解下。一、使用nohup和&amp;假设现在我们有一个服务xxxx.jar，需要放到后台运行，我们可以这么操作：12bash# nohup java -jar xxxx.jar &amp;#运行上面这条命令就可以将xxxx.jar这个服务放到后台去运行了。 二、使用bg如果我们忘记使用nohup和&amp;,怎么办呢？莫慌，还可以这么操作：123#使用Ctrl + z,将服务暂停。bash# bg#然后执行bg命令就将服务放到后台运行了。 三、查看现在在后台运行的进程1234bash# jobs -l#运行jobs -l将列出在后台的进程bash# fg %num#运行fg %num将进程移到前台来，注意不是pid。]]></content>
      <categories>
        <category>linux</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ELK 使用系列 三、kibana创建visualize]]></title>
    <url>%2FELK-%E4%BD%BF%E7%94%A8%E7%B3%BB%E5%88%97-%E4%B8%89%E3%80%81kibana%E5%88%9B%E5%BB%BAvisualize.html</url>
    <content type="text"><![CDATA[前两节已经搭建完ELK,那怎么从这些nginx日志中提取出对我们有用的信息呢。本节就来讲解一下：(以统计http状态码为例)一、登录kibana页面，点击Visualize，点击+号创建 二、点击饼图pie 三、按照如图所示配置 四、点击三角标按钮，就可以出图了。五、以此为例，依次创建uri请求平均时间，ip访问次数统计等等图表。六、将这些图表添加到dashboard，效果如下图所示。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gitlab升级]]></title>
    <url>%2Fgitlab%E5%8D%87%E7%BA%A7.html</url>
    <content type="text"><![CDATA[gitlab属于比较重要的服务，需要时常关注安全问题，官方有安全更新时，都应该尽快进行升级。升级步骤：(这里主要基于yum和apt-get升级)1.关闭unicorn，sidekiq和nginx服务123gitlab-ctl stop unicorngitlab-ctl stop sidekiqgitlab-ctl stop nginx 2.备份gitlab1gitlab-rake gitlab:backup:create 3.升级gitlab1234#centos7yum update gitlab-ce#ubuntuapt-get install gitlab-ce 4.启动unicorn，sidekiq和nginx服务123gitlab-ctl start unicorngitlab-ctl start sidekiqgitlab-ctl start nginx]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ELK 使用系列 二、logstash和filebeat安装]]></title>
    <url>%2FELK-%E4%BD%BF%E7%94%A8%E7%B3%BB%E5%88%97-%E4%BA%8C%E3%80%81logstash%E5%92%8Cfilebeat%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[上一节讲到elasticsearch和kibana的安装，这一节就来讲logstash和fielbeat安装。一、filebeat的安装和配置filebeat的作用就是日志采集，将采集到的日志发送到中间件，我这边以redis为例，也可以用其他的(kafka)等等。123bash# wget https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.7.0-linux-x86_64.tar.gzbash# tar xf filebeat-6.7.0-linux-x86_64.tar.gz -C /usr/local/bash# ln -s /usr/local/filebeat-6.7.0-linux-x86_64 /usr/local/filebeat 编辑/usr/local/filebeat/filebeat.yml进行配置12345678910111213141516171819#vim /usr/local/filebeat/filebeat.ymlfilebeat.inputs:- type: log paths: - /data/logs/nginx/*/*.log #nginx日志 - /data/logs/xxxx/*/*.log #自主应用的日志 #处理异常日志，合并成一行，方便查看 multiline.pattern: '^method|^params|^data|^[[:space:]]&#123;2,4&#125;|^Traceback|.*Error:|^[[:space:]]+at|^Caused by:|.*Exception' multiline.negate: false multiline.match: after fields: feature: test-host-192.168.1.2 #自定义字段,用于区分服务器#redis地址output.redis: hosts: ["192.168.1.3"] port: 6379 password: "" 将filebeat做成系统服务，filebeat.service文件内容如下：12345678910111213141516171819202122232425262728293031323334353637383940bash# vim /etc/systemd/system/filebeat.yml# It is not recommended to modify this file in-place, because it will# be overwritten during package upgrades. If you want to add further# options or overwrite existing ones then use# See "man systemd.service" for details.# Note that almost all daemon options could be specified in[Unit]Description=Filebeat ServiceAfter=network.target[Service]ExecStart=/usr/local/filebeat/filebeat -c /usr/local/filebeat/filebeat.ymlUser=rootType=simpleRestart=on-failure# Hardening measures##################### Provide a private /tmp and /var/tmp.PrivateTmp=true# Mount /usr, /boot/ and /etc read-only for the process.#ProtectSystem=full# Disallow the process and all of its children to gain# new privileges through execve().#NoNewPrivileges=true# Use a new /dev namespace only populated with API pseudo devices# such as /dev/null, /dev/zero and /dev/random.#PrivateDevices=true# Deny the creation of writable and executable memory mappings.#MemoryDenyWriteExecute=true[Install]WantedBy=multi-user.target 二、安装logstashlogstash服务负责将redis的数据读取出来，经过处理写到elasticsearch。123bash# wget https://artifacts.elastic.co/downloads/logstash/logstash-6.7.0.tar.gzbash# tar xf logstash-6.7.0.tar.gz -C /usr/local/bash# ln -s /usr/local/logstash-6.7 /usr/local/logstash 编辑/usr/local/logstash/config/client-redis.conf进行配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566bash# vim /usr/local/logstash/config/client-redis.confinput &#123; redis &#123; host =&gt; "192.168.1.3" port =&gt; "6379" key =&gt; "filebeat" data_type =&gt; "list" password =&gt; "" threads =&gt; 10 &#125;&#125;filter&#123; ####将nginx日志和自主应用日志分开处理 if "/data/logs/nginx" in [source] &#123; grok &#123; patterns_dir =&gt; "/usr/local/logstash/patterns" match =&gt; &#123; "message" =&gt; "%&#123;NGINXACCESS&#125;" &#125; &#125; geoip &#123; source =&gt; "remote_addr" &#125; date &#123; match =&gt; [ "log_timestamp" , "dd/MMM/YYYY:HH:mm:ss Z" ] target =&gt; "@timestamp" &#125; &#125;else&#123; grok &#123; match =&gt; &#123;"message" =&gt; "(?&lt;datetime&gt;\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;\s\d&#123;2&#125;:\d&#123;2&#125;:\d&#123;2&#125;\.\d&#123;3&#125;)"&#125; &#125; date &#123; match =&gt; ["datetime", "yyyy-MM-dd HH:mm:ss.SSS"] target =&gt; "@timestamp" &#125; if [source] =~ "api" or [source] =~ "admin" &#123; ruby &#123; code =&gt; "event.set('timestamp', event.get('@timestamp').time.localtime - 8*60*60)" &#125; ruby &#123; code =&gt; "event.set('@timestamp', event.get('timestamp'))" &#125; &#125; &#125;&#125;###nginx和自主应用分别使用不同的模版和indexoutput &#123; if "/data/logs/nginx" in [source] &#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:10086"] index =&gt; "logstash-nginx-%&#123;+YYYY.MM.dd&#125;" template =&gt; "/usr/local/logstash/config/nginx-template.json" template_name =&gt; "wb-nginx" template_overwrite =&gt; true &#125; &#125;else&#123; elasticsearch &#123; hosts =&gt; ["127.0.0.1:10086"] index =&gt; "logstash-%&#123;+YYYY.MM.dd&#125;" template =&gt; "/usr/local/logstash/config/app-template.json" template_name =&gt; "wb_index" template_overwrite =&gt; true &#125; &#125; stdout &#123;codec =&gt; rubydebug&#125;&#125; 编辑/usr/local/logstash/config/nginx-template.json12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455bash# vim /usr/local/logstash/config/nginx-template.json&#123; "aliases": &#123;&#125;, "index_patterns": [ "logstash-nginx-*" ], "mappings": &#123; "doc": &#123; "properties": &#123; "body_bytes_sent": &#123; "type": "long" &#125;, "request_length": &#123; "type": "long" &#125;, "remote_addr": &#123; "type": "ip" &#125;, "x_forword_for": &#123; "type": "keyword" &#125;, "geoip": &#123; "dynamic": true, "properties": &#123; "location": &#123; "type": "geo_point" &#125; &#125;, "type": "object" &#125;, "request_time": &#123; "type": "float" &#125;, "upstream_response_time": &#123; "type": "float" &#125;, "upstream_status": &#123; "type": "integer" &#125;, "http_status": &#123; "type": "integer" &#125; &#125; &#125; &#125;, "order": 1, "version": 60001, "settings": &#123; "index": &#123; "number_of_shards": "1", "number_of_replicas": "0", "refresh_interval": "5s" &#125; &#125;&#125; 编辑/usr/local/logstash/config/app-template.json12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273bash# vim /usr/local/logstash/config/app-template.json&#123; "order": 1, "version": 60002, "index_patterns": [ "logstash-*" ], "settings": &#123; "index": &#123; "refresh_interval": "5s", "number_of_shards": 1, "number_of_replicas": 0 &#125; &#125;, "mappings": &#123; "_default_": &#123; "dynamic_templates": [ &#123; "message_field": &#123; "path_match": "message", "match_mapping_type": "string", "mapping": &#123; "type": "text", "norms": false &#125; &#125; &#125;, &#123; "string_fields": &#123; "match": "*", "match_mapping_type": "string", "mapping": &#123; "type": "text", "norms": false, "fields": &#123; "keyword": &#123; "type": "keyword", "ignore_above": 256 &#125; &#125; &#125; &#125; &#125; ], "properties": &#123; "@timestamp": &#123; "type": "date" &#125;, "@version": &#123; "type": "keyword" &#125;, "geoip": &#123; "dynamic": true, "properties": &#123; "ip": &#123; "type": "ip" &#125;, "location": &#123; "type": "geo_point" &#125;, "latitude": &#123; "type": "half_float" &#125;, "longitude": &#123; "type": "half_float" &#125; &#125; &#125; &#125; &#125; &#125;, "aliases": &#123;&#125;&#125; 编辑nginx日志的匹配模版文件123456789101112131415161718192021bash# mkdir /usr/local/logstash/patternsbash# vi /usr/local/logstash/patterns/nginxURIPARM1 [A-Za-z0-9$.+!*'|()&#123;&#125;,~@#%&amp;/=:;^\\_&lt;&gt;`?\-\[\]]*URIPATH1 (?:/[\\A-Za-z0-9$.+!*'()&#123;&#125;,~:;=@#% \[\]_&lt;&gt;^\-&amp;?]*)+HOSTNAME1 \b(?:[0-9A-Za-z_\-][0-9A-Za-z-_\-]&#123;0,62&#125;)(?:\.(?:[0-9A-Za-z_\-][0-9A-Za-z-:\-_]&#123;0,62&#125;))*(\.?|\b)STATUS ([0-9.]&#123;0,3&#125;[, ]&#123;0,2&#125;)+HOSTPORT1 (%&#123;IP&#125;:%&#123;POSINT&#125;[, ]&#123;0,2&#125;)+FORWORD (?:%&#123;IP&#125;[,]?[ ]?)+|%&#123;WORD&#125;URIPARM [A-Za-z0-9$.+!*'|()&#123;&#125;,~@#%&amp;/=:;_?\-\[\]]*URIPATH (?:/[A-Za-z0-9$.+!*'()&#123;&#125;,~:;=@#%&amp;_\- ]*)+URI1 (%&#123;URIPROTO&#125;://)?(?:%&#123;USER&#125;(?::[^@]*)?@)?(?:%&#123;URIHOST&#125;)?(?:%&#123;URIPATHPARAM&#125;)?NGINXACCESS %&#123;IPORHOST:remote_addr&#125; - (%&#123;USERNAME:user&#125;|-) \[%&#123;HTTPDATE:log_timestamp&#125;\] \"%&#123;WORD:request_method&#125; %&#123;URIPATH1:uri&#125; HTTP/%&#123;NUMBER:http_version&#125;\" %&#123;BASE10NUM:http_status&#125; (?:%&#123;BASE10NUM:body_bytes_sent&#125;|-) \"(?:%&#123;GREEDYDATA:http_referrer&#125;|-)\" \"(%&#123;GREEDYDATA:user_agent&#125;|-)\" \"(%&#123;FORWORD:x_forword_for&#125;|-)\" \"(%&#123;FORWORD:x_real_ip&#125;|-)\" \"(%&#123;IPORHOST:domain&#125;|%&#123;URIHOST:domain&#125;|-)\" \"(%&#123;IPORHOST:http_x_host&#125;|%&#123;URIHOST:http_x_host&#125;|-)\" \"(%&#123;BASE16FLOAT:request_time&#125;|-)\" \"(?:%&#123;BASE10NUM:request_length&#125;|-)\" \"(?:%&#123;HOSTPORT1:upstream_addr&#125;|-)\" \"(%&#123;BASE16FLOAT:upstream_response_time&#125;|-)\" \"(%&#123;BASE10NUM:upstream_status&#125;|-)\" nginx的日志格式为1234log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for" "$http_x_real_ip" "$host" "$http_x_host" "$request_time" "$request_length" ' '"$upstream_addr" "$upstream_response_time" "$upstream_status"'; 使用supervisor进行管理logstash进程12345678910111213141516171819bash# vim /etc/supervisor.d/logstash.ini[program:logstash]directory=/usr/local/logstashcommand=/usr/local/logstash/bin/logstash -f /usr/local/logstash/config/client-redis.confenvironment=JAVA_HOME=/usr/local/jdk/user=onecafeautostart=trueautorestart=truestartretries=1startsecs=1redirect_stderr=truestdout_logfile=/data/logs/logstash/logstash.logstdout_logfile_maxbytes=5MBstdout_logfile_backups=5stderr_logfile=/data/logs/logstash/logstash-err.logstderr_logfile_maxbytes=5MBstderr_logfile_backups=5stopasgroup=truekillasgroup=true 三、启动logstash和filebeat12bash# systemctl start filebeatbash# supervisorctl start logstash 到这边，整个elk就算搭建好，下一节继续讲解kibana的使用。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ELK 使用系列:一、ELK安装]]></title>
    <url>%2FELK-%E4%BD%BF%E7%94%A8%E7%B3%BB%E5%88%97-%E4%B8%80%E3%80%81ELK%E5%AE%89%E8%A3%85.html</url>
    <content type="text"><![CDATA[现在许多公司都开始使用ELK进行日志的收集，分析以及展示。今天我就讲讲ELK的安装，后续会继续深入讲解。一、安装环境123系统：centos7配置：2核8GJDK版本：1.8.0_191 二、安装步骤1234567#下载最新版elasticsearch,kibana,logstashbash# wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.7.0.tar.gzbash# wget https://artifacts.elastic.co/downloads/kibana/kibana-6.7.0-linux-x86_64.tar.gzbash# tar xf elasticsearch-6.7.0.tar.gz -C /usr/local/bash# tar xf kibana-6.7.0-linux-x86_64.tar.gz -C /usr/local/bash# ln -s /usr/local/elasticsearch-6.7.0 /usr/local/elasticsearchbash# ln -s /usr/local/kibana-6.7.0 /usr/local/kibana 三、配置elastcisearch12345678#打开/usr/local/elasticsearch/config/elasticsearch.ymlbash# vim /usr/local/elasticsearch/config/elasticsearch.yml修改如下内容：cluster.name: test-elastic #这个可以自己取名path.data: /data/elastic/data #存储数据的目录，可自定义path.logs: /data/elastic/logs #存储日志的目录，可自定义network.host: 127.0.0.1 #监听的iphttp.port: 10086 #监听的http端口 123456#打开/usr/local/elasticsearch/config/jvm.optionsbash# vim /usr/local/elasticsearch/config/jvm.options修改如下内容：-Xms4g-Xmx4gPS.根据服务器配置可以相应调整内存参数。 创建目录1bash#mkdir -p /data/elastic/&#123;data,logs&#125; 因为elastci不能使用root用户启动，新建一个普通用户12bash# useradd ybhbash# chown -R ybh.ybh /data/elastic /usr/local/elasticsearch /usr/local/kibana 四、配置kibana1234567#打开/usr/local/kibana/config/kibana.ymlbash# vim /usr/local/kibana/config/kibana.yml修改如下内容：server.port: 10087 #kibana 监听端口server.host: "0.0.0.0" #kibana 监听地址elasticsearch.url: "http://localhost:10086" #elasticsearch的地址elasticsearch.requestTimeout: 300000 #elasticsearch 超时时间 五、安装supervisor使用supervisor来管理kibana,做成后台服务，方便管理12345678910111213141516171819bash# yum install supervisorbash# vim /etc/supervisord.d/kibana.ini添加如下内容：[program:kibana]directory=/usr/local/kibanacommand=/usr/local/kibana/bin/kibana serve -c /usr/local/kibana/config/kibana.ymluser=ybhautostart=trueautorestart=truestartretries=1startsecs=1redirect_stderr=truestdout_logfile=/data/logs/kibana/kibana.logstdout_logfile_maxbytes=5MBstdout_logfile_backups=5stopasgroup=truekillasgroup=truebash# mkdir -p /data/logs/kibanabash# chown -R ybh.ybh /data/logs 六、启动elasticsearch,kibana123bash# cd /usr/local/elasticsearch/binbash# ./elasticsearch -dbash# supervisorctl start kibana 七、验证12345678910111213141516171819bash# curl http://127.0.0.1:10086&#123; "name" : "iS7URyg", "cluster_name" : "test-elastic", "cluster_uuid" : "U1vyeKlnSoSoQXitZ5r0SQ", "version" : &#123; "number" : "6.7.0", "build_flavor" : "default", "build_type" : "tar", "build_hash" : "fe40335", "build_date" : "2018-10-30T23:17:19.084789Z", "build_snapshot" : false, "lucene_version" : "7.4.0", "minimum_wire_compatibility_version" : "5.6.0", "minimum_index_compatibility_version" : "5.0.0" &#125;, "tagline" : "You Know, for Search"&#125;PS.当出现如上字样，表示elasticsearch启动成功了。 访问http://ip:10087，看是否成功，如果成功，将看到如下页面 logstash需要与filebeat一起进行配置，才能起作用，后续再来。]]></content>
      <categories>
        <category>ELK</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx配置跨域请求]]></title>
    <url>%2Fnginx%E9%85%8D%E7%BD%AE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82.html</url>
    <content type="text"><![CDATA[当出现403跨域错误的时候 No ‘Access-Control-Allow-Origin’ header is present on the requested resource，需要给Nginx服务器配置响应的header参数： 一、解决方案只需要在Nginx的配置文件中配置以下参数：12345678910111213141516171819server &#123; ..... ..... if ($http_origin ~* "^http://192.168.1.39:8080$") &#123; set $cors_origin $http_origin; &#125; add_header 'Access-Control-Allow-Origin' $cors_origin always; add_header 'Access-Control-Allow-Credentials' 'true' always; add_header 'Access-Control-Allow-Headers' 'Accept, Authorization,DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type'; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; location / &#123; if ($request_method = 'OPTIONS') &#123; return 204; &#125; try_files $uri $uri/ /index.php$is_args$args; &#125; ....&#125; 二、解释1. Access-Control-Allow-Origin1服务器默认是不被允许跨域的。给Nginx服务器配置`Access-Control-Allow-Origin *`后，表示服务器可以接受所有的请求源（Origin）,即接受所有跨域的请求。 2. Access-Control-Allow-Headers 是为了防止出现以下错误：123Request header field Content-Type is not allowed by Access-Control-Allow-Headers in preflight response.这个错误表示当前请求Content-Type的值不被支持。其实是我们发起了"application/json"的类型请求导致的。这里涉及到一个概念：预检请求（preflight request）,请看下面"预检请求"的介绍。 3. Access-Control-Allow-Methods 是为了防止出现以下错误：1Content-Type is not allowed by Access-Control-Allow-Headers in preflight response. 4. Access-Control-Allow-Credentials1Access-Control-Allow-Credentials 头指定了当浏览器的credentials设置为true时是否允许浏览器读取response的内容。当用在对preflight预检测请求的响应中时，它指定了实际的请求是否可以使用credentials。请注意：简单 GET 请求不会被预检；如果对此类请求的响应中不包含该字段，这个响应将被忽略掉，并且浏览器也不会将相应内容返回给网页。 5.给OPTIONS 添加 204的返回，是为了处理在发送POST请求时Nginx依然拒绝访问的错误1发送"预检请求"时，需要用到方法 OPTIONS ,所以服务器需要允许该方法。 三、 预检请求（preflight request）其实上面的配置涉及到了一个W3C标准：CROS,全称是跨域资源共享 (Cross-origin resource sharing)，它的提出就是为了解决跨域请求的。1跨域资源共享(CORS)标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 其实Content-Type字段的类型为application/json的请求就是上面所说的搭配某些 MIME 类型的 POST 请求,CORS规定，Content-Type不属于以下MIME类型的，都属于预检请求：123application/x-www-form-urlencodedmultipart/form-datatext/plain 所以 application/json的请求 会在正式通信之前，增加一次”预检”请求，这次”预检”请求会带上头部信息 Access-Control-Request-Headers: Content-Type：12345OPTIONS /api/test HTTP/1.1Origin: http://foo.exampleAccess-Control-Request-Method: POSTAccess-Control-Request-Headers: Content-Type... 省略了一些 服务器回应时，返回的头部信息如果不包含Access-Control-Allow-Headers: Content-Type则表示不接受非默认的的Content-Type。即出现以下错误：1Request header field Content-Type is not allowed by Access-Control-Allow-Headers in preflight response.]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[gitlab服务器迁移]]></title>
    <url>%2Fgitlab%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%81%E7%A7%BB.html</url>
    <content type="text"><![CDATA[公司之前的gitlab搭在阿里云上，考虑到安全问题，需要将gitlab迁移到本地服务器。下面记录下步骤：1.迁移准备工作和思路:从a服务器迁移到b服务器,由于Gitlab自身的兼容性问题，高版本的Gitlab无法恢复低版本备份的数据,需要注意在b服务器部署和a服务器一样版本的gitlab,部署好环境后开始备份和数据迁移。12#查看gitlab版本号gitlab-rake gitlab:env:info 2.备份原gitlab服务器的数据12gitlab-rake gitlab:backup:create RAILS_ENV=production#PS: 备份后的文件一般是位于/var/opt/gitlab/backups下, 自动生成文件名文件名如1553575861_2019_03_26_11.4.3-ee_gitlab_backup.tar 3.将步骤2生成的tar文件拷贝到本地服务器上相应的backups目录下12scp username@src_ip:/var/opt/gitlab/backups/1553575861_2019_03_26_11.4.3-ee_gitlab_backup.tar /var/opt/gitlab/backups#PS: username为原服务器的用户名，src_ip原服务器IP地址 4.在本地服务器上恢复数据12345#PS:gitlab恢复数据时需要将1553575861_2019_03_26_11.4.3-ee_gitlab_backup.tar改名为1553575861_gitlab_backup.tar#将1553575861_gitlab_backup.tar更改属主属组为git.gitmv 1553575861_2019_03_26_11.4.3-ee_gitlab_backup.tar 1553575861_gitlab_backup.tarchown git.git 1553575861_gitlab_backup.targitlab-rake gitlab:backup:restore RAILS_ENV=production BACKUP=1553575861]]></content>
      <categories>
        <category>gitlab</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[jenkins获取凭据密码]]></title>
    <url>%2Fjenkins%E8%8E%B7%E5%8F%96%E5%87%AD%E6%8D%AE%E5%AF%86%E7%A0%81.html</url>
    <content type="text"><![CDATA[本人忘记jenkins上的gitlab CI/CD的账号密码，经过google一番搜索，可以使用以下方式找回密码，在此记录，以防忘记。12341.登录jenkins,进入凭据页面2.点击需要找回密码的账号，进入编辑页面3.打开浏览器的开发者模式，将密码框的type=password去掉，这时密码框会显示加密过的密码，将这串密码记录下来。4.打开http://&#123;jenkins_url&#125;/script,进入script console界面，在输入框输入println( hudson.util.Secret.decrypt("$password") )，其中$password 就是记录下来的密码，点击Run。密码已经出来了。]]></content>
      <categories>
        <category>jenkins</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[pip设置国内源]]></title>
    <url>%2Fpip%E8%AE%BE%E7%BD%AE%E5%9B%BD%E5%86%85%E6%BA%90.html</url>
    <content type="text"><![CDATA[因为某个不可描述的墙，导致pip下载包异常的慢，所以需要把pip的源改成国内的。下面列举几个国内的源:123456http://pypi.douban.com/ 豆瓣http://pypi.hustunique.com/ 华中理工大学http://pypi.sdutlinux.org/ 山东理工大学http://pypi.mirrors.ustc.edu.cn/ 中国科学技术大学http://mirrors.aliyun.com/pypi/simple/ 阿里云https://pypi.tuna.tsinghua.edu.cn/simple/ 清华大学 具体配置如下：123#在当前用户主目录创建.pip文件夹&gt;cd ~&gt;mkdir .pip 12345#在.pip目录创建并编辑pip.conf#pip安装需要使用的https加密，所以在此需要添加trusted-host [global]trusted-host = mirrors.ustc.edu.cnindex-url = https://mirrors.ustc.edu.cn/pypi/web/simple]]></content>
      <categories>
        <category>python</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[nginx try_files配置详解]]></title>
    <url>%2Fnginx-try-files%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[Nginx try_files配置123location / &#123; try_files $uri $uri/ / ;&#125; 解释：在项目目录下匹配$uri这个路径，如果有存在文件，则返回该文件，如果不存在该文件，则匹配目录，还没有的话，直接返回首页。]]></content>
      <categories>
        <category>nginx</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[devops]]></title>
    <url>%2Fdevops.html</url>
    <content type="text"><![CDATA[testtest1123function foo() &#123;echo "这是一段牛逼的代码"&#125;]]></content>
      <categories>
        <category>devops</category>
      </categories>
  </entry>
</search>
